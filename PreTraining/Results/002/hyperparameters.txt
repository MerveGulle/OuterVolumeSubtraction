### HYPERPARAMETERS
params = dict([('num_epoch', 100),
               ('batch_size', 1),
               ('learning_rate', 3e-4),
               ('num_training_slice', 'all'),
               ('num_validation_slice', 'all'),
               ('num_test_slice', 'all'),
               ('num_workers', 0),          # It should be 0 for Windows machines
               ('use_cpu', False)])                  # number of iterations  

optimizer = torch.optim.Adam(denoiser.parameters(),lr=params['learning_rate'])
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)

# composite kspace
undersampled kspace
# sensitivity maps
generated with espirit
# noiseless images
reference = np.sum(composite_images*np.conj(sense_maps),3)
# noisy image
_, Nx, Ny, Nc = composite_images.shape
std = 0.005
noisy_images = composite_images + np.random.normal(0, std, [1,Nx,Ny,Nc]) + 1j*np.random.normal(0, std, [1,Nx,Ny,Nc])
noisy = np.sum(noisy_images*np.conj(sense_maps),3)
