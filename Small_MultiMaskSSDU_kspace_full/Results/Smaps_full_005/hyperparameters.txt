Training is done until epoch 100. 
5 ssdu masks are used

### HYPERPARAMETERS

undersampled data
kspace,full
Smaps,full

RealTime_fromPK/short_axis_data

### HYPERPARAMETERS
params = dict([('num_epoch', 100),
               ('batch_size', 1),
               ('learning_rate', 1e-4),
               ('num_training_slice', 'all'),
               ('num_validation_slice', 'all'),
               ('num_workers', 0),          # It should be 0 for Windows machines
               ('use_cpu', False),
               ('num_mask', 5),             # number of masks
               ('T', 10)])                  # number of iterations

scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)

loss: Normalized L1 - L2 loss
test subjects: 3,8

model_shared_weights.py: RB convolution layers have same coefficients

Pretrained after: C:\Codes\p006_OVS\OVS\PreTraning\Results\002\model\PreTrainedResNet_200.pt

L = 0.0356 (100th epoch)